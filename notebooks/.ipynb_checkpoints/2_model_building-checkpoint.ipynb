{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutinal Neural Network for Classifying Cars\n",
    "\n",
    "### Background\n",
    "Stanford AI has developed a dataset of cars with make, model and year. The aim of this project is to classify cars as accurately as possible using a convolutional neural network. We will use the Keras package with Tensorflow backend to run model training, and we will validate and evaluate the accuracy of the model based on the parameters.\n",
    "\n",
    "### Contents\n",
    "1. Build the classifier layers\n",
    "2. Load training and test data\n",
    "3. Run training\n",
    "4. Evaluate model accuracy\n",
    "\n",
    "Improving:https://github.com/CihanBosnali/Real-Time-Cars-Classification-Using-Keras/blob/master/model_trainer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model A: Classifying Make and Model\n",
    "<b>Aim</b>: Classify a car as part of the 196 classes in our dataset in terms of both make and model year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build the Classifier\n",
    "\n",
    "We will use 3 convolution layers for the sake of computing power, with all layers using the relu activation function. We use this function because of it's non-linear (compared to sigmoid, for example, which can cause neurons to 'vanish'). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'img_pixels': 256,\n",
    "          'n_filters': 64,\n",
    "          'layer_nodes': 512,\n",
    "          'batchsize': 32,\n",
    "          'epochs': 5,\n",
    "          'kernel_size': (4,4),\n",
    "          'pool_size': (2,2),\n",
    "          'dropout':0.2,\n",
    "          'steps_per_epoch': 100,\n",
    "          'validation_steps': 5\n",
    "          }\n",
    "\n",
    "# config\n",
    "img_pixels = config['img_pixels']\n",
    "n_filters = config['n_filters']\n",
    "layer_nodes = config['layer_nodes']\n",
    "batchsize = config['batchsize']\n",
    "epochs = config['epochs']\n",
    "kernel_size = config['kernel_size']\n",
    "pool_size = config['pool_size']\n",
    "dropout = config['dropout']\n",
    "steps_per_epoch = config['steps_per_epoch']\n",
    "validation_steps = config['validation_steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = 0\n",
    "fs = 0\n",
    "for _, dirnames, filenames in os.walk(\"../scraped_images_2020/train\"):\n",
    "  # ^ this idiom means \"we won't be using this value\"\n",
    "    folders += len(dirnames)\n",
    "    fs += len(filenames)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "616"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39783"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "car_classifier = Sequential()\n",
    "#Adding 1st Convolution and Pooling Layer\n",
    "car_classifier.add(Conv2D(n_filters,kernel_size=kernel_size,input_shape=(img_pixels,img_pixels,3),activation='relu'))\n",
    "car_classifier.add(MaxPool2D(pool_size=pool_size))\n",
    "car_classifier.add(Dropout(dropout))\n",
    "#Adding 2nd Convolution and Pooling Layer\n",
    "car_classifier.add(Conv2D(n_filters,kernel_size=kernel_size,activation='relu'))\n",
    "car_classifier.add(MaxPool2D(pool_size=pool_size))\n",
    "car_classifier.add(Dropout(dropout))\n",
    "#Adding 3rd Convolution and Pooling Layer\n",
    "car_classifier.add(Conv2D(n_filters,kernel_size=kernel_size,activation='relu'))\n",
    "car_classifier.add(MaxPool2D(pool_size=pool_size))\n",
    "car_classifier.add(Dropout(dropout))\n",
    "#Adding 4th Convolution and Pooling Layer\n",
    "car_classifier.add(Conv2D(n_filters,kernel_size=kernel_size,activation='relu'))\n",
    "car_classifier.add(MaxPool2D(pool_size=pool_size))\n",
    "car_classifier.add(Dropout(dropout))\n",
    "#Adding 5th Convolution and Pooling Layer\n",
    "car_classifier.add(Conv2D(n_filters,kernel_size=kernel_size,activation='relu'))\n",
    "car_classifier.add(MaxPool2D(pool_size=pool_size))\n",
    "car_classifier.add(Dropout(dropout))\n",
    "\n",
    "#Flatten\n",
    "car_classifier.add(Flatten())\n",
    "\n",
    "#Adding Input and Output Layer\n",
    "car_classifier.add(Dense(units=layer_nodes,activation='relu'))\n",
    "car_classifier.add(Dense(units=layer_nodes,activation='relu'))\n",
    "car_classifier.add(Dense(units=layer_nodes,activation='relu'))\n",
    "car_classifier.add(Dense(units=folders,activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, clipvalue=0.5)\n",
    "car_classifier.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39783 images belonging to 616 classes.\n",
      "Found 12577 images belonging to 616 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data agumentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory('../scraped_images_2020/train',\n",
    "                                               target_size=(img_pixels,img_pixels),\n",
    "                                               batch_size=batchsize,\n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=True,\n",
    "                                               seed=42)\n",
    "\n",
    "test_data = test_datagen.flow_from_directory('../scraped_images_2020/test',\n",
    "                                             target_size=(img_pixels,img_pixels),\n",
    "                                             batch_size=1,\n",
    "                                             class_mode='categorical',\n",
    "                                             shuffle=True,\n",
    "                                             seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 1121s 11s/step - loss: 6.4253 - acc: 0.0025 - val_loss: 6.4232 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 1247s 12s/step - loss: 6.4226 - acc: 0.0031 - val_loss: 6.4191 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 1153s 12s/step - loss: 6.4206 - acc: 0.0037 - val_loss: 6.4203 - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 3039s 30s/step - loss: 6.4214 - acc: 0.0047 - val_loss: 6.4213 - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      " 61/100 [=================>............] - ETA: 5:12:51 - loss: 6.4159 - acc: 0.0087"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0310 09:19:35.043719 56064 ultratb.py:149] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "E0310 09:19:35.423724 56064 ultratb.py:149] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "E0310 09:19:35.566728 56064 ultratb.py:149] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = car_classifier.fit_generator(train_data,\n",
    "                                       steps_per_epoch=steps_per_epoch,\n",
    "                                       epochs=epochs,\n",
    "                                       validation_data=test_data,\n",
    "                                       validation_steps=validation_steps\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame.from_dict(history.history)\n",
    "metrics = pd.concat([pd.Series(range(0,30),name='epochs'),metrics],axis=1)\n",
    "metrics.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = metrics.reset_index().drop('epochs', axis=1).rename(columns={'index': 'epochs'})\n",
    "metrics['config'] = str(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = car_classifier.to_json()\n",
    "with open(\"../models/cars_classifier_tuned_100eP_50ba_1ba(val).json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "car_classifier.save_weights(\"../models/cars_classifier_tuned_100eP_50ba_1ba(val).h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "metrics.to_csv(\"../models/cars_classifier_metrics2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test model on a single image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('models/cars_classifier_untuned.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"models/cars_classifier_untuned.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load single prediction image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "test_image = image.load_img('../car_data/single_prediction/bmw_3series.jpg', target_size=(img_pixels, img_pixels))\n",
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to array and expand_dims because we are only doing 1 image prediction\n",
    "test_image_array = image.img_to_array(test_image)\n",
    "test_image_expand = np.expand_dims(test_image_array, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classes = car_classifier.predict(test_image_expand, batch_size=1)\n",
    "\n",
    "results = {}\n",
    "iterator = 0\n",
    "for key in train_data.class_indices:\n",
    "    results.setdefault(key, classes[0][iterator])\n",
    "    iterator+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(results, orient='index').sort_values(0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Accuracy of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.tools import FigureFactory as FF\n",
    "from plotly.tools import get_embed\n",
    "from plotly import offline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"../models/cars_classifier_metrics.csv\")\n",
    "\n",
    "results.drop('epochs', axis=1, inplace=True)\n",
    "results.rename(columns={'Unnamed: 0': 'epochs'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.262903</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>5.279155</td>\n",
       "      <td>0.005632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.170683</td>\n",
       "      <td>0.013360</td>\n",
       "      <td>5.202109</td>\n",
       "      <td>0.008648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.142595</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>5.143253</td>\n",
       "      <td>0.010056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.115322</td>\n",
       "      <td>0.017409</td>\n",
       "      <td>5.115203</td>\n",
       "      <td>0.012671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.052454</td>\n",
       "      <td>0.016802</td>\n",
       "      <td>5.062903</td>\n",
       "      <td>0.016383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epochs  val_loss   val_acc      loss       acc\n",
       "0       0  5.262903  0.010400  5.279155  0.005632\n",
       "1       1  5.170683  0.013360  5.202109  0.008648\n",
       "2       2  5.142595  0.011800  5.143253  0.010056\n",
       "3       3  5.115322  0.017409  5.115203  0.012671\n",
       "4       4  5.052454  0.016802  5.062903  0.016383"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training vs Validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~himi64/16.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<chart_studio.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_x = results['epochs']\n",
    "random_y0 = results['acc']\n",
    "random_y1 = results['val_acc']\n",
    "\n",
    "# Create traces\n",
    "trace0 = go.Scatter(\n",
    "    x = random_x,\n",
    "    y = random_y0,\n",
    "    mode = 'lines',\n",
    "    name = 'Training Accuracy'\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x = random_x,\n",
    "    y = random_y1,\n",
    "    mode = 'lines',\n",
    "    name = 'Validation Accuracy'\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=go.layout.Title(\n",
    "        text='Training vs Validation Accuracy',\n",
    "        xref='paper',\n",
    "        x=0\n",
    "    ),\n",
    "    xaxis=go.layout.XAxis(\n",
    "        title=go.layout.xaxis.Title(\n",
    "            text='Epochs',\n",
    "            font=dict(\n",
    "                family='Courier New, monospace',\n",
    "                size=18,\n",
    "                color='#7f7f7f'\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    yaxis=go.layout.YAxis(\n",
    "        title=go.layout.yaxis.Title(\n",
    "            text='Accuracy',\n",
    "            font=dict(\n",
    "                family='Courier New, monospace',\n",
    "                size=18,\n",
    "                color='#7f7f7f'\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace0, trace1]\n",
    "acc_fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(acc_fig, filename='line-mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../../hm9464.github.io/site/plots/train_val_acc_algo1.html'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offline.plot(acc_fig, filename='../plots/train_val_acc_algo1.html')\n",
    "offline.plot(acc_fig, filename='../../../hm9464.github.io/site/plots/train_val_acc_algo1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~himi64/16.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<chart_studio.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_x = results['epochs']\n",
    "random_y0 = results['loss']\n",
    "random_y1 = results['val_loss']\n",
    "\n",
    "# Create traces\n",
    "trace0 = go.Scatter(\n",
    "    x = random_x,\n",
    "    y = random_y0,\n",
    "    mode = 'lines',\n",
    "    name = 'Training Loss'\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x = random_x,\n",
    "    y = random_y1,\n",
    "    mode = 'lines',\n",
    "    name = 'Validation Loss'\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=go.layout.Title(\n",
    "        text='Training vs Validation Loss',\n",
    "        xref='paper',\n",
    "        x=0\n",
    "    ),\n",
    "    xaxis=go.layout.XAxis(\n",
    "        title=go.layout.xaxis.Title(\n",
    "            text='Epochs',\n",
    "            font=dict(\n",
    "                family='Courier New, monospace',\n",
    "                size=18,\n",
    "                color='#7f7f7f'\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "    yaxis=go.layout.YAxis(\n",
    "        title=go.layout.yaxis.Title(\n",
    "            text='Loss',\n",
    "            font=dict(\n",
    "                family='Courier New, monospace',\n",
    "                size=18,\n",
    "                color='#7f7f7f'\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace0, trace1]\n",
    "loss_fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(loss_fig, filename='line-mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../../hm9464.github.io/site/plots/train_val_loss_algo1.html'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offline.plot(loss_fig, filename='../plots/train_val_loss_algo1.html')\n",
    "offline.plot(loss_fig, filename='../../../hm9464.github.io/site/plots/train_val_loss_algo1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model B: Classifying Make only\n",
    "\n",
    "<b>Aim</b>: Preidct the make of a car using the input image (e.g. BMW, Honda, etc).\n",
    "\n",
    "For this model, we will need to aggregate our existing training and prediction dataset into make ONLY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
